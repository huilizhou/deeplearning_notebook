#### Mini-batch 梯度下降
之前，我们介绍的神经网络训练过程是针对m个样本，称为batch，通过向量化计算方式，同时进行的。如果m很大，例如达到百万数量级，训练速度往往会很慢，因为每次迭代度要对所有样本进行求和运算和矩阵运算，我们将这种梯度下降算法称为Batch Gradient Descent。

解释一下这个算法的名称，batch 梯度下降法指的是我们之前讲过的梯度下降法算法，
就是同时处理整个训练集，这个名字就是来源于能够同时看到整个batch训练集的样本被处理，这个名字不怎么样，但就是这样叫它。 

相比之下，mini-batch梯度下降法，指的是我们在下一张幻灯片中会讲到的算法，你每次同时处理的单个的 mini-batch X<sup>{t}</sup>和Y<sup>{t}</sup>，而不是同时处理全部的X和Y练集。 

为了解决这一问题，我们可以把m个训练样本分成若干个子集，称为mini-batches，这一样每个子集包含的数据量就小了，例如只有1000，这样在每次在单一子集上进行神经网络训练，速度就会大大提高。这种梯度下降算法叫做Mini-batch Gradient Descent。

假设总的训练样本个数为m=5000000，其维度为(n<sub>x</sub>,m)。将其划分为5000个子集，每个mini-batch含有1000个样本。我们将每个mini-batch 记为X<sup>{t}</sup>，其维度为（n<sub>x</sub>,1000)。相应的每个mini-batch的输出记为Y<sup>{t}</sup>，其维度为(1,1000)，且t=1,2,...5000。

- X<sup>(i)</sup>:第i个样本
- Z<sup>[l]</sup>:神经网络第l层网络的线性输出
- X<sup>{t}</sup>,Y<sup>{t}</sup>:第t组mini-batch

Mini-batches Gradient Descent 的实现过程是先将总的训练样本分成T个子集(mini-batches)，然后对每个mini-batch进行神经网络训练，包括 Forward Propagation, Compute Cost Function, Back Propagation,循环至T个mini-batch都训练完毕。

```math
for\ \ t=1,\cdots,T\ \ \{

\ \ \ \ Forward\ Propagation

\ \ \ \ Compute Cost Function

\ \ \ \ Backward Propagation

\ \ \ \ W:=W-\alpha\cdot dW

\ \ \ \ b:=b-\alpha\cdot db

\}
```
这是使用mini-batch 梯度下降法训练样本的第一步，我写下的代码也可被称为进行“一代”(1 epoch)的训练。一代这个词代表意味着只是一次遍历了训练集。

使用batch梯度下降法，一次遍历训练集只能让你做一个梯度下降，使用mini-batch 梯度下降法，一次遍历训练集，能让你做5000个梯度下降。当然正常来说，你想要多次遍历训练集，还需要为另一个while循环设置另一个for循环。所以你可以一直处理遍历训练集，直到最后你能收敛到一个合适的精度。

如果你有一个丢失的数据集，mini-batch梯度下降法比batch梯度下降法运行地更快，我们将进一步深入讨论mini-batch 梯度下降算法。

值得一提的是，对于Mini-Batches Gradient Descent，可以进行多次epoch训练。而且，每次epoch，最好是将总体训练数据重新打乱、重新分成T组mini-batches，这样有利于训练出最佳的神经网络模型。

---
#### 理解mini-batch 梯度下降法
![image](https://pic3.zhimg.com/80/v2-4cd211474fdc2b1c5643b80de3144bb3_hd.jpg)

使用batch梯度下降法时，每次迭代你都需要遍历整个数据集，可以预期每次迭代成本都会下降，所以如果成本函数J是迭代次数的一个函数，它应该会随着每次迭代而减少，如果J在某次迭代中增加了，那肯定出了问题，也许你的学习率太大了。

使用mini-batch 梯度下降法，如果你作出成本函数在整个过程中的图，并不是每次迭代都下降的，特别是每次迭代中，你要处理的是X<sup>{t}</sup>,y<sup>{t}</sup>有关，也就是说，每次迭代下，你都在训练不同的样本集或者说训练不同的mini-batch，如果你要作出J<sup>{t}</sup>的图，因为在训练mini-batch 梯度下降法时，会经过多少代，你可能会看到这样的曲线，没有每次迭代都下降是不要紧的，但走势应该向下，噪声产生的原因在于也许X<sup>{1}</sup>和Y<sup>{1}</sup>是比较容易计算的mini-batch，因此成本会低一些，不过由于出于偶然，X<sup>{2}</sup>和Y<sup>{2}</sup>是比较难运算的mini-batch.或许你需要一些残缺的样本，这样一来，成本会高些，所以才会出现这些摆动。

你需要决定的变量之一是mini-batch的大小，m就是训练集的大小，极端情况下：

如果mini-batch的大小等于m，其实就是batch梯度下降法，你就有了mini-batch X<sup>{1}</sup>,Y<sup>{1}</sup>，并且该mini-batch等于整个训练集，所以mini-batch 大小设为m可以得到batch梯度下降法。

另一个极端的情况，假设mini-batch大小为1。就有了新的算法，叫做随机梯度下降法，每个样本都是独立的mini-batch,当你看的第一个mini-batch=时，也就是X<sup>{1}</sup>和Y<sup>{1}</sup>，如果mini-batch 大小为1，它就是你看到的第一个训练样本。接着看第二个mini-batch，也就是第二个训练样本，采取梯度下降的步骤，然后是第三个训练样本，以此类推，一次只处理一个。

看在两种极端下成本函数的优化情况，如果这是你想要最小化的成本函数的轮廓，最小值在那里，batch 梯度下降法从某处开始，相对噪声低些，幅度也大一些，你可以继续找最小值。 

相反，在随机梯度下降法中，从某一点开始，我们重新选取一个起始点，每次迭代，你只对一个样本进行梯度下降，大部分时候你向着全局最小值靠近，有时候你会远离最小值，因为那个样本恰好给你指的方向不对，因此随机梯度下降法是有很多噪声的，平均来看，它最终会靠近最小值，不过有时候也会方向错误，因为随机梯度下降法永远不会收敛，而是会一直在最小值附近波动，但它并不会在达到最小值并停留在此。 

实际上你选择的mini-batch 大小在1和m之间，而1太小了，m太大了，原因在于如果使用batch梯度下降法，mini-batch 的大小为m，每个迭代需要处理大量的训练样本，该算法的主要弊端在于特别是在训练样本数量巨大的时候，单次迭代耗时太长了，如果训练样本不大，batch梯度下降法运行地很好。

相反，如果使用随机梯度下降法，如果你只要处理一个样本，那这个方法很好，这样做没有问题，通过减小学习率，噪声会被改善或有所减小，但随机梯度下降法的一大缺点是，你会失去所有向量化带给你的加速，因为一次性只处理了一个训练样本，这样效率过于低下。

实践中最好选取不大不小的mini-batch尺寸，实际上学习率最快，你会发现两个好处，一方面，你得到了大量的向量化。另一方面，你不需要等待整个训练集被处理完就可以进行后续工作。

如果mini-batch 的大小既不是1也不是m，应该取中间值，选择m是有指导原则的。

首先如果训练集过小，直接使用batch梯度下降法，样本集较小就没有必要使用mini-batch梯度下降法，你可以快速训练整个训练集，所以使用batch梯度下降法也很好。这里说的少 一般是指小于2000，这样比较适合使用batch梯度下降法。一般的mini-batch设置为64到512，一般为2的n次方。

最后要注意的是在你的mini-batch 中，要确保你的X<sup>{t}</sup>和Y<sup>{t}</sup>要符合CPU/GPU的内存，取决于你的应用方向以及训练集的大小。如果你处理的 mini-batch 和 CPU/GPU 内存不相符，不管你用什么方法处理数据，你会注意到算法的表现急转直下变得惨不忍睹，所以我希望你对一般人们使用的 mini-batch 大小有一个直观了解。事实上 mini-batch 大小是另一个重要的变量，你需要做一个快速尝试，才能找到能够最有效地减少成本函数的那个，我一般会尝试几个不同的值，几个不同的 2 次方，然后看能否找到一个让梯度下降优化算法最高效的大小。希望这些能够指导你如何开始找到这一数值。


---
#### 指数加权平均法
指数加权平权，在统计中也称为指数加权移动平均。

举个例子，记录半年内伦敦市的气温变化，并在二维平面上绘制出来。

![image](https://pic2.zhimg.com/v2-0ae2f94a905e3a0ef04cf7c0fdb73238_r.jpg)

看上去，温度数据似乎有noise，而且抖动较大。如果我们希望看的半年内气温的整体变化趋势，可以通过移动平均的方法来对每天的气温进行平滑处理。

例如我们可以假设V<sub>0</sub>=0，当成第0天的气温值。第一天的气温于第0天的气温有关：

```math
V_1=0.9*V_0+0.1*\theta_1
```
第二天的气温与第一天的气温有关：

```math
V_2=0.9*V_1+0.1*\theta_2
=0.9*(0.9*V_0+0.1*\theta_1)+0.1*\theta_2
=0.9^2V_0+0.9*0.1*\theta_1+0.1*\theta_2
```
第三天的气温与第二天的气温有关：

```math
V_3=0.9*V_2+0.1*\theta_3
=0.9*(0.9^2V_0+0.9*0.1*\theta_1+0.1*\theta_2)+0.1*\theta_3
=0.9^3V_0+0.9^2*0.1*\theta_1+0.9*0.1*\theta_2+0.1*\theta_3
```
即第t天与第t-1天的气温迭代关系为：

```math
V_t=0.9*V_{t-1}+0.1\theta_t
=0.9^tV_0+0.9^{t-1}*0.1*\theta_1+0.9^{t-2}*0.1*\theta_2+...+0.9*0.1*\theta_{t-1}+0.1*\theta_t
```
经过移动平均处理得到的气温如下图红色曲线所示：
![image](https://pic1.zhimg.com/v2-f7d3e7925fce0db64e4ef6f58b9c65b2_r.jpg)

这种滑动平均算法称为指数加权平均(exponentially weighted average。根据之前的推导公式，其一般形式为：

```math
V_t=\beta*V_{t-1}+(1-\beta)\theta_t
```
上面的例子中，&beta;=0.9。&beta;值决定了指数加权平均的天数，近似表示为：

```math
1\over{1-\beta}
```
例如，当&beta;=0.9，则1/1-&beta;=10，表示将前10天进行指数加权平均。当&beta;=0.98，则1/1-&beta;=50，表示对前50天进行指数加权平均。&beta;值越大，则指数加权平均的天数越多，平均后的趋势线就越平缓，但是同时也会向右平移。下图绿色曲线和黄色曲线分别表示了&beta;=0.98和&beta;=0.5时，指数加权平均的结果。

这个高值𝛽要注意几点，你得到的曲线要平坦一些，原因在于你多平均了几天的温度，所以这个曲线，波动更小，更加平坦，缺点是曲线进一步右移，因为现在平均的温度值更多，要平均更多的值，指数加权平均公式在温度变化时，适应地更缓慢一些，所以会出现一定延迟，因为当𝛽 = 0.98，相当于给前一天的值加了太多权重，只有 0.02 的权重给了当日的值，所以温度变化时，温度上下起伏，当𝛽较大时，指数加权平均值适应地更缓慢一些。 

如果𝛽是另一个极端值，比如说 0.5，这是平均了2天的温度，由于仅仅平均了2天的温度，平均的数据太少了，所以得到的曲线有更多的噪声，有可能出现异常值，但是这个曲线能够更快的适应温度变化。

![image](https://pic4.zhimg.com/v2-ed09d0dbdf3329254cf53657dc6b914a_r.jpg)

这里简单解释一下
公式1/1-&beta;是怎么来的，准确的说，指数加权平均算法根之前所有天的数值都有关系，根据之前的推导公式就能看出。但是指数是衰减的，一般认为衰减到1/e 就可以忽略不计了。因此根据之前推导的公式，只要证明：

```math
\beta^{1\over {1-\beta}}={1\over e}

```
令
```math
{1\over {1-\beta}}=N,
N>0
```
则

```math
\beta=1-{1\over N},
{1\over N}<1
```
即证明：

```math
(1-{1\over N})^N={1\over e}
```
显然当N>>0时，上述等式成立。
至此简单解释了为什么指数加权平均的天数的公式为1/1-&beta;

---
#### 理解指数加权平均
我们讲到了指数加权平均数，这是几个优化算法中的关键一环，而这几个优化算法能帮助你训练神经网络。本视频中，我希望进一步探讨算法的本质作用。 
回忆一下这个计算指数加权平均数的关键方程：

```math
V_t=\beta V_{t-1}+(1-\beta)\theta_t
```
我们进一步地分析，来理解如何计算出每日温度的平均值。

𝛽 = 0.9的时候，得到的结果是红线，如果它更接近于 1，比如 0.98，结果就是绿线，如果𝛽小一点，如果是 0.5，结果就是黄线。 
![image](https://pic4.zhimg.com/v2-ed09d0dbdf3329254cf53657dc6b914a_r.jpg)

使𝛽 = 0.9，写下相应的几个公式，所以在执行的时候，𝑡从 0 到 1 到 2 到 3，𝑡的值在不
断增加，为了更好地分析，我写的时候使得𝑡的值不断减小，然后继续往下写。 

```math
v_{100}=0.9v_{99}+0.1\theta_{100}

v_{99}=0.9v_{98}+0.1\theta_{99}

v_{98}=0.9v_{97}+0.1\theta_{98}

...
```

```math
v_{100}=0.1\theta_{100}+0.1*0.9\theta_{99}+0.1*(0.9)^2\theta_{98}+0.1*(0.9)^3\theta_{97}+...
```
所以这是一个加和并平均，100号数据，也就是当日温度。我们分析𝑣<sub>100</sub>的组成，也就是在一年第100天计算的数据，但是这个是总和，包括 100 号数据，99号数据，97号数据等等。画图的一个办法是，假设我们有一些日期的温度，所以这是数，这是𝑡，所以100号数据有个数值，99号数据有个数值，98号数据等等，𝑡为 100，99，98等等，这就是数日的温度数值。 
 
 然后我们构建一个指数衰减函数，从 0.1 开始，到0.1×0.9，到0.1×(0.9)2，以此类推，所以就有了这个指数衰减函数。 
 
 ![image](https://pic4.zhimg.com/v2-6d1f3025d3b701bdecc0b49df560f0eb_r.jpg)
 
 最后你也许要问，到底需要平均几天的温度，实际上(0.9)<sup>10</sup>大约为0.35，这大约是1/e。e 是自然算法的基础之一。大体上说，如果有 1−𝜀，在这个例子中，𝜀=0.1，所以1−𝜀=0.9。
指数加权平均的好处之一在于，它占用极少的内存，电脑内存只占用一行数字而已，然后把最新数据 代入公式，不断覆盖就可以了，它基本上只占用一行代码，计算指数加权平均数也只占用单行数字的存储和内存，当然它并不是最好的，也不是最精准的计算平均数的方法。如果你要计算移动窗，你直接算出过去 10 天的总和，过去 50 天的总和，除以10和50就好，如此往往会得到更好的估测。但缺点是，如果保存所有最近的温度数据，和过去 10 天的总和，必须占用更多的内存，执行更加复杂，计算成本也更加高昂。

---
#### 指数加权平均的偏差修正
你学会如何计算指数加权平均数，有一个技术名词叫做偏差修正，可以让平均数运算更加准确。

![image](https://pic3.zhimg.com/v2-308ae272b30db39820af2065934b3346_r.jpg)

我们注意到，紫色曲线与绿色曲线的区别是，紫色曲线相对较低一些，这是因为开始时，我们设置V<sub>0</sub>=0，所以初始值会相对小一点儿，直到后面受前面的影响逐渐变小，趋于正常。

修正这种问题的方法是进行偏移校正(bias correction)，即在每次计算完V<sub>t</sub>后，对V<sub>t</sub>进行下式处理。：

```math
V_t\over {1-\beta^t}
```
举个例子，当t=2时，1-&beta;<sup>2</sup>=1-0.98<sup>2</sup>=0.0396，因此对第二天温度的估测变为了

```math
{v_2\over 0.0396}={{0.0196\theta_1+0.02\theta_2}\over 0.0396}
```
也就是&theta;<sub>1</sub>和&theta;<sub>2</sub>的加权平均数，并去除偏差，你会发现，随着t的增加，&beta;<sup>t</sup>接近于0，所以当t很大的时候，偏差修正几乎没有什么作用，因此当t较大的时候，紫线和绿线基本重合了。不过在开始学习阶段，你才开始预测热身练习，偏差修正可以帮助你更好预测温度，偏差修正可以帮助你使结果从紫线变成绿线。 

在机器学习中，在计算指数加权平均数的大部分时候，大家不在乎执行偏差修正，因为大部分人宁愿熬过初始时期，拿到具有偏差的估测，然后继续计算下去。如果你关心初始时期的偏差，在刚开始计算指数加权移动平均数的时候，偏差修正能帮助你在早期获取更好的估测。 


---
#### 动量梯度下降法
还有一种算法叫做Momentum，或者叫做动量梯度下降法，运行速度几乎总是快于标准的梯度下降算法，简而言之，基本的想法就是计算梯度的指数加权平均数，并利用该梯度更新权重W和常数项b。

![image](https://pic3.zhimg.com/v2-f0a77a3a985b7d0ee1ebe79c125ff4d3_r.jpg)

原始的梯度下降算法如上图蓝色折线所示。在梯度下降的过程中，梯度下降的振荡较大，尤其对于W、b之间数值范围差别较大的情况。此时每一点处的梯度只与当前方向有关，产生类似折线的效果，前进缓慢。而如果对梯度进行指数加权平均，这样使得当前梯度的不仅与当前方向有关，还与之前的方向有关，这样处理梯度前进方向更加平滑，减少振荡，能够更快地到达最小值处。

权重W和常数项b的指数加权平均表达式如下：

```math
V_{dW}=\beta·V_{dW}+(1-\beta)·dW

V_{db}=\beta·V_{db}+(1-\beta)·db
```
从动量角度来看，以权重W为例，V<sub>dW</sub>可以看成速度V，dW可以看成加速度a。指数加权平均实际上是计算当前的速度，当前速度由之前的速度和现在的加速度共同影响。而&beta;< 1，又能限制速度V<sub>dW</sub>过大。也就是说，当前的速度是渐变的，而不是瞬变的，是动量过程，这保证了梯度下降的平稳性和准确性，减少振荡，较快地到达最小值处。

动量梯度下降算法的过程如下：

```math
On iteration t:

    Compute\, dW,\,db \,on\, the \,current\, mini-batch
    
    V_{dW}=\beta V_{dW}+(1-\beta)dW
    
    V_{db}=\beta V_{db}+(1-\beta)db
    
    W=W-\alpha V_{dW}, 
    b=b-\alpha V_{db}
    

```
初始时，令V<sub>dW</sub>=0,V<sub>db</sub>=0。一般设置&beta;=0.9，即指数加权平均前10天的数据，实际应用效果更好。

另外，关于偏移校正，可以不使用，因为经过10次迭代后，随着滑动平均的过程，偏移情况会逐渐消失。

---
#### RMSprop算法
我们知道动量(Momentum)可以加快梯度下降，还有一个叫做RMSprop(root mean square prop)算法，也可以加速梯度下降。

回忆一下，我们之前的例子，如果你执行梯度下降，虽然横轴方向正在推进，但纵轴方向会有大幅度摆动，为了分析这个例子，假设纵轴代表参数b，横轴代表参数W，可能有W<sub>1</sub>,W<sub>2</sub>或者其他重要参数，为了便于理解，被称为b和W。

所以你想减缓b方向的学习，即纵轴方向，同时加快，至少不是减缓横轴方向的学习，RMSprop算法可以实现这一点。

![image](https://pic3.zhimg.com/v2-fbc62d5643928f56edf1e0b007a91d97_r.jpg)

在第t次迭代中，该算法会照常计算当下mini-batch的微分dW和db，所以我会保留这个指数加权平均数，我们利用新的符号S<sub>dW</sub>，而不是V<sub>dW</sub>。因此

```math
S_{dW}=\beta S_{dW}+(1-\beta)dW^2
```
澄清一下，**这个平方操作是针对这一整个符号的**，这样做能够保留微分平方的加权平均数，同样

```math
S_{db}=\beta S_{db}+(1-\beta)db^2
```
再说一次，**平方是针对整个符号的操作**。

接着RMSprop会这样更新参数值，

```math
W:=W-a{dW\over {\sqrt{S_{dW}}}}

b:=b-a{db\over {\sqrt{S_{db}}}}
```
我们来理解一下它的原理，记得在横轴方向或者例子中的W方向，我们希望加快学习速度，而在垂直方向，也就是例子中的b方向，我们希望减缓纵轴上的摆动，所以有了S<sub>dW</sub>和S<sub>db</sub>，我们希望S<sub>dW</sub>会相对较小，所有我们要除以一个较小的数，希望S<sub>db</sub>会相对较大，所有我们要除以一个较大的数，

，所以这些微分中，𝑑𝑏较大，𝑑𝑊较小，因为函数的倾斜程度，在纵轴上，也就是 b 方向上要大于在横轴上，也就是𝑊方向上。𝑑𝑏平方较大，所以𝑆<sub>𝑑𝑏</sub>也会较大，而相比之下，𝑑𝑊会小一些，亦或𝑑𝑊平方会小一些，因此𝑆𝑑<sub>𝑊</sub>会小一些，结果就是纵轴上的更新要被一个较大的数相除，就能消除摆动，而水平方向的更新则被较小的数相除。 

RMSprop 的影响就是你的更新最后会变成这样（绿色线），纵轴方向上摆动较小，而横轴方向继续推进。还有个影响就是，你可以用一个更大学习率𝑎，然后加快学习，而无须在纵轴上垂直方向偏离。

要说明的一点是，我们一直把纵轴和横轴方向分别称为b和W，只是为了方便展示而已。实际中，你会处于参数的高维度空间，所以需要消除摆动的垂直维度，你需要消除摆动，实际上是参数W<sub>1</sub>，W<sub>2</sub>等的合集，水平维度可能是W<sub>3</sub>，W<sub>4</sub>等等，因此把W和b分开只是为了方便说明。实际中𝑑𝑊是一个高维度的参数向量，𝑑𝑏也是一个高维度参数向量，但是你的直觉是，在你要消除摆动的维度中，最终你要计算一个更大的和值，这个平方和微分的加权平均值，所以你最后去掉了那些有摆动的方向。所以这就是 RMSprop，全称是均方根，因为你将微分进行平
方，然后最后使用平方根。 
 
最后再就这个算法说一些细节的东西，然后我们再继续。下一个视频中，我们会将RMSprop 和 Momentum 结合起来，我们在Momentum中采用超参数𝛽，为了避免混淆，我们现在不用𝛽，而采用超参数𝛽<sup>2</sup>以保证在Momentum和RMSprop中采用同一超参数。要确保你的算法不会除以0，如果𝑆𝑑𝑊的平方根趋近于0。为了确保数值稳定，在实际操练的时候，你要在分母上加上一个很小很小的𝜀，𝜀是多少没关系10<sup>-8</sup>是个不错的选择，这只是保证数值能稳定一些，无论什么原因，你都不会除以一个很小很小的数。

所以RMSprop跟Momentum有很相似的一点，可以消除梯度下降中的摆动，包括mini-batch梯度下降，并允许你有一个更大的学习率，从而加速你的算法学习速度。

---
#### Adam 优化算法
在深度学习的历史上，包括许多知名研究者在内，提出了优化算法，并很好地解决了一些问题，但随后这些优化算法被指出并不能一般化，并不适用于多种神经网络，时间久了，深度学习圈子里的人开始多少有些质疑全新的优化算法，很多人都觉得动量（Momentum）梯度下降法很好用，很难再想出更好的优化算法。所以 RMSprop 以及 Adam 优化算法（Adam优化算法也是本视频的内容），就是少有的经受住人们考验的两种算法，已被证明适用于不同的深度学习结构。

Adam优化算法基本说就是将Momentum 和RMSprop结合在一起，那么看看如何使用Adam算法。

```math
V_{dW}=0,S_{dW}=0,V_{db}=0,S_{db}=0

On\, iteration \, t:
    Compute dW,db
    
    V_{dW}=\beta_1V_{dW}+(1-\beta_1)dW,V_{db}=\beta_1V_{db}+(1-\beta_1)db
    
    S_{dW}=\beta_2S_{dW}+(1-\beta_2)(dW)^2,S_{db}=\beta_2S_{db}+(1-\beta_2)(db)^2
    
    V_{dW}^{corrected}={V_{dW} \over 1-\beta_1^t},V_{db}^{corrected}={V_{db} \over 1-\beta_1^t}
    
    S_{dW}^{corrected}={S_{dW} \over 1-\beta_2^t},S_{db}^{corrected}={S_{db} \over 1-\beta_2^t}
    
    W:=W-\alpha {V_{dW}^{corrected}\over {\sqrt {S_{dW}^{corrected}}}+\varepsilon }
    
    b:=b-\alpha {V_{db}^{corrected}\over {\sqrt {S_{db}^{corrected}}}+\varepsilon }
    
```
Adma算法中包含了几个超参数，分别是&alpha;,&beta;<sub>1</sub>,&beta;<sub>2</sub>,&varepsilon;。其中， &beta;<sub>1</sub>通常设置为0.9， &beta;<sub>2</sub> 通常设置为0.999， &varepsilon;通常设置为 10<sup>-8</sup> 。一般只需要对&beta;<sub>1</sub>,&beta;<sub>2</sub>进行调试。

实际应用中，Adam算法结合了动量梯度下降和RMSprop各自的优点，使得神经网络训练速度大大提高。

为什么这个算法叫做Adam? Adam代表的是Adaptive Moment Estimation，&beta;<sub>1</sub>用于计算这个微分(dW)，叫做第一矩，&beta;<sub>2</sub>用来计算平方数的指数加权平均数((dW)<sup>2</sup>)，叫做第二矩，所以称为Adam的名字由来，但是大家都简称Adam权威算法。

---
#### 学习率衰减
减小学习因子&alpha;也能有效的提高神经网络训练的速度，这种方法被称为learning rate decay。

Learning rate decay 就是随着迭代次数的增加，学习因子&alpha;逐渐减小。下面用图示法来解释这样做的好处。

![image](https://pic1.zhimg.com/v2-5e3c34d62e2508cc7e929507184ac644_r.jpg)

蓝色折线代表使用恒定的学习因子&alpha;，由于每次训练&alpha;相同，步进长度不变，在接近最优值处的振荡也不大，在最优值附近较大范围内振荡，与最优值距离比较远。绿色折线表示使用不断减小的&alpha;，随着训练次数增加，&alpha;逐渐减小，步进长度减小，使得能够在最优值处较小范围内微弱振荡，不断逼近最优值。相对比较恒定的&alpha;来说，learning rate decay更接近最优值。

learning rate decay中对&alpha;可由下列公式得到：

```math
\alpha={1 \over {1+decay\_rate*epoch}}\alpha_0
```
其中，decay_rate是参数(可调)，epoch是训练完所有样本的次数。随着epoch增加，&alpha;会不断减小。

除了上面计算&alpha;的公式之外，还有其他可供选择的计算公式。


```math
\alpha=0.95^{epoch}·\alpha_0

\alpha={k\over {\sqrt {epoch}}}·\alpha_0 
\, or \, {k\over {\sqrt t}}·\alpha_0 
```
其中，k为可调参数，t为mini-bach number

有时人们也会用一个离散下降的学习率，也就是某个步骤有某个学习率，一会儿之后，学习率减少一半，一会儿又减少一半，一会儿又一半。这就是离散下降的意思。

到现在，我们讲了一些公式，看学习率&alpha;究竟如何随时间变化，人们有时侯还会做一件事即手动衰减。只有模型小的时候，有可能有用。

学习率&alpha;并不是我们尝试的要点，设定一个固定的&alpha;然后好坏调整，会有很大的影响，学习率的衰减的确大有裨益，有时候可以加快训练。但并不是我们首要尝试的内容。

---
#### 局部最优
在深度学习研究早期，人们总是担心优化算法会困在极差的局部最优，不过随着深度学习理论不断发展，我们对局部最优的理解也发生了改变。

![image](https://pic4.zhimg.com/v2-6d39e64779ab860636a23eb182a85993_r.jpg)

左边是人们在想局部最优时脑海里浮出来的图，也许你想优化一些参数，我们把它称为W<sup>1</sup>,W<sup>2</sup>，平面的高度就是损失函数。在图中似乎分布着局部最优，梯度下降法或者其他某个算法可能会困在一个局部最优中，而不会抵达全局最优。

事实上，如果你要创建一个神经网络，通常梯度为0的点并不是图中的局部最优点，实际上，成本函数的零梯度点，通常就是鞍点。

但是一个具有高维度空间的函数，如果梯度为0，那么在每个方向，它可能是凸函数，也可能是凹函数。如果你在2万维空间中，那么想要得到局部最优，所有的2万个方向都需要这样，但发生的几率也许会很小。你更有可能遇到的有些方向的曲线会这样向上弯曲，另一些曲线向下弯，而不是都向上弯曲，因此在高维度空间，你更可能碰到鞍点。

所以我们从深度学习历史中学到的一课就是，我们对低维度空间的大部分直觉，比如你可以画出上面的图，并不能应用到高维度空间中。适用于其它算法，因为如果你有 2 万个参数，那么𝐽函数有 2 万个维度向量，你更可能遇到鞍点，而不是局部最优点。

总的来说，关于local optima，有两点总结：
1. 只要选择合理的强大的神经网络，一般不太可能陷入local optima。
2. Plateaus 可能会使梯度下降变慢，降低学习速度。
