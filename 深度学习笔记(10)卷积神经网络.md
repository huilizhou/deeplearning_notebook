#### 计算机视觉
机器视觉(computer version)是深度学习应用的主要方向之一。一般CV问题包括以下三类：
- Image classification 
- Object Detection 
- Neural Style transfer 

下图展示了一个神经风格转换(Neural Style Transfer )的例子：

![image](https://pic2.zhimg.com/80/v2-9e45e96b99a28f6f3da546ef9c0f4bb0_hd.jpg)

使用传统神经网络处理机器视觉的一个主要问题是输入层维度很大。例如一张64x64x3的图片，神经网络输入层的维度为12288。如果尺寸较大，例如一张1000x1000x3的图片，神经网络输入层的维度将达到3百万，使得网络权重W非常庞大。这样会造成两个后果，一是神经网络结构复杂，数据量相对不够，容易出现过拟合；二是所需内存、计算量较大。解决这一问题的方法就是使用卷积神经网络(CNN)。

---
#### 边缘检测示例
对于CV问题，我们之前在笔记中介绍过，神经网络由浅层到深层，分别可以检测出图片的边缘特征，局部特征(例如眼睛和鼻子等)、整体面部轮廓。

![image](https://pic1.zhimg.com/80/v2-18b50ee7dac5a638f2dbe6d8c6ab53d2_hd.jpg)

本节我们介绍的如何检测图片的边缘。

最常见的检测图片边缘有两类：一是垂直边缘(vertical edges)，二是水平边缘(horizontal edges)。

![image](https://pic4.zhimg.com/v2-c1122b8c1239d1e2fd6cc2badfbd74c7_r.jpg)

图片的边缘检测可以通过相应滤波器进行卷积操作来实现，原始图片尺寸为6x6，滤波器filter尺寸为3x3，卷积后的图片尺寸为4x4，得到结果如下：

![image](https://pic2.zhimg.com/v2-5aa4e3e1ae441345b239ec374c2da8ba_r.jpg)

顺便提一下，*表示卷积操作。python中，卷积用conv_forward()表示；tensorflow中，卷积用tf.nn.conv2d()表示；keras中，卷积用Conv2D()表示。

Vertical edge detection能够检测图片的垂直边缘。下图对应一个垂直边缘检测的例子：

![image](https://pic2.zhimg.com/v2-cc336984cf1c7642a00fdde09b255d9d_r.jpg)

如果把最右边的矩阵当成图像，它是这个样子的。在中间有段亮一点的区域，对应检查到这个6x6图像中间的垂直边缘。这里的维数似乎有点不太正确，检测到的边缘太粗了。因为在这个例子中，图片太小了。如果你用一个1000x1000的图像，而不是6x6的图片，你会发现，其很好地检测出图像中的垂直边缘，从垂直边缘检测中可以得到的启发是，因为我们使用的3x3的矩阵(过滤器)，所以垂直边缘是个3x3的区域，左边是明亮的元素，中间的并不需要考虑，右边是深色像素。在这个6x6图像的中间部分，明亮的像素在左边，深色的像素在右边，就被视为一个垂直边缘，卷积运算提供了一个方便的方法来发现图像中的垂直边缘。

---
#### 更多边缘检测内容
图片边缘有两种渐变模式，一种是由明变暗，一种是由暗变明。以垂直边缘检测为例，下图展示两种方式的区别。实际应用中，在这两种渐变方式并不影响边缘检测结果，可以对输出图片取绝对值操作，得到同样的结果。

![image](https://pic2.zhimg.com/v2-b571fd56c1535387d7a63f3da63ef003_r.jpg)

垂直边缘检测和水平边缘检测的滤波器算子如下所示：

![image](https://pic2.zhimg.com/v2-55adb56db3dc09d6b13dc8f1ed5dd364_r.jpg)

下面展示一个水平边缘检测的例子：

![image](https://pic1.zhimg.com/80/v2-a4663229125dc223216b93eb50658d7e_hd.jpg)

除了上面提到的这种简单的Vertical、Horizontal滤波器之外，还有其它常用的filters，例如Sobel filter和Scharr filter。这两种滤波器的特点是增加图片中心区域的权重。

![image](https://pic3.zhimg.com/80/v2-02b8d32f238dec368554cc3733886850_hd.jpg)

上图展示的是垂直边缘检测算子，水平边缘检测算子只需将上图顺时针翻转90度即可。

在深度学习中，如果我们想检测图片的各种边缘特征，而不限于垂直边缘和水平边缘，那么filter的数值一般需要通过模型训练得到，类似于标准神经网络中的权重W一样由梯度下降算法反复迭代求得。CNN的主要的目的就是计算出这些filter的数值。确定得到这些filter后，CNN浅层网络，也就实现了对图片所有的边缘特征的检测。

---
#### padding
按照我们上面所讲的图片卷积，如果原始尺寸为nxn，filter尺寸为fxf，则卷积之后的图片尺寸为(n-f+1)x(n-f+1)，注意f一般为基数。这样会带来两个问题：
- 卷积运算后，输出图片尺寸缩小
- 原始图片边缘信息对输出贡献很小，输出图片丢失边缘信息。

为了解决图片缩小的问题，可以使用padding的方法，即把原始图片尺寸进行扩展，扩展区域补零，用p来表示每个方向扩展的宽度。

![image](https://pic3.zhimg.com/v2-4558ecba4705e4abfdd01f87b867b207_r.jpg)

经过padding之后，原始图片的尺寸为(n+2p)x(n+2p)，filter 尺寸为fxf，则卷积之后的图片尺寸为(n+2p-f+1)x(n+2p-f+1)。

若要保证卷积前后图片尺寸不变，则应满足：

```math
p={f-1 \over 2}
```
没有padding操作，p=0，我们称之为"Valid convoluitons";有padding操作，p=(f-1)/2，我们称之为"Same convolutions"。

---
#### 卷积步长
Stride 表示filter 在原图中水平方向和垂直方向每次前进的步进长度。之前我们默认为stride=1。若stride=2，则表示filter每次步进长度为2，即隔一点移动一次。

![image](https://pic4.zhimg.com/v2-4fc4e2876edba9269204c389058322fe_r.jpg)

我们用s表示stride长度，p表示padding长度，如果原始图片尺寸为n x n，filter尺寸为f x f，则卷积后的图片尺寸为：

```math
\lfloor {{n+2p-f}\over s} +1\rfloor X
\lfloor {{n+2p-f}\over s} +1\rfloor
```
上式中&lfloor;...&rfloor;表示向下取整。

值得一提的是，相关系数（cross-correlations）与卷积（convolutions）之间是有区别的。实际上，真正的卷积运算会先将filter绕其中心旋转180度，然后再将旋转后的filter在原始图片上进行滑动计算。filter旋转如下所示：

![image](https://pic4.zhimg.com/v2-5acc15642d6a0c9b1b5d103c5fd96b13_r.jpg)

比较而言，相关系数的计算过程则不会对filter进行旋转，而是直接在原始图片上进行滑动计算。

其实，目前为止我们介绍的CNN卷积实际上计算的是相关系数，而不是数学意义上的卷积。但是，为了简化计算，我们一般把CNN中的这种“相关系数”就称作卷积运算。之所以可以这么等效，是因为滤波器算子一般是水平或垂直对称的，180度旋转影响不大；而且最终滤波器算子需要通过CNN网络梯度下降算法计算得到，旋转部分可以看作是包含在CNN模型算法中。总的来说，忽略旋转运算可以大大提高CNN网络运算速度，而且不影响模型性能。

卷积运算服从分配律：

```math
(A*B)*C=A*(B*C)
```

---
#### 卷积为何有效
对于3通道的RGB图片，其对应的滤波器算子同样也是3通道的。例如一个图片是6x6x3，分别变送图片的高度(height)、宽度(weight)和通道(#channel)。

3通道的图片卷积运算与单通道图片的卷积运算基本一致。过程是将每个单通道(R、G、B)与对应的filter进行卷积运算求和，然后再将3通道的和相加，得到输出图片的一个像素值。

为了计算这个卷积操作的输出，你要做的是把这个3x3x3的过滤器先放到最左上角的位置，这个3x3x3的过滤器有27个数，27个参数也就是3的立方。依次取这27个数，然后乘以相应的红绿蓝通道中的数字。先取红色通道的前9个数字，然后是绿色通道，然后是蓝色通道，乘以左边黄色立方体覆盖对应的27个数，然后把这些数都加起来，就得到了输出的第一个数字。

![image](https://pic1.zhimg.com/80/v2-c84cebc13e94e5684fcb51c3a37af4dd_hd.jpg)

不同通道的滤波算子可以不相同。例如R通道filter实现垂直边缘检测，G和B通道不进行边缘检测，全部置零，或者将R，G，B三通道filter全部设置为水平边缘检测。

为了进行多个卷积运算，实现更多边缘检测，可以增加更多的滤波器组。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。这样，不同滤波器组卷积得到不同的输出，个数由滤波器组决定。

我们让6x6x3的图像和这个3x3x3的过滤卷积，得到4x4的输出，(第一个)这可能是一个垂直边界检测器或者是学习检测其他的特征，第二个过滤器可以用橘色表示，它可以表示一个水平边缘检测器。

![image](https://pic4.zhimg.com/v2-7866a39bb4eb76a68b5c5a704609c7f2_r.jpg)

所以和第一个过滤卷积一样，可以得到一个4x4输出，然后第二个过滤器得到一个不同的输出，取第一个输出放到前面，然后取第二个输出放在后面，把两个输出堆叠在一起，这一你就得到了一个4x4x2的输出立方体，它用6x6x3的图像，然后卷积上两个不同的3x3的过滤器，得到4x4的输出，它们堆叠在一起形成了4x4x2的立方体，这里的2来源于我们用了2个滤波器。

若输入图片的尺寸为nxnxn<sub>c</sub>，其中n<sub>c</sub>为图片通道数目，然后卷积上一个fxfxn<sub>c</sub>，按照惯例，前一个n<sub>c</sub>和后一个n<sub>c</sub>必须数值相同。然后你就得到了一个(n-f+1)x(n-f+1)xn<sub>c'</sub>，其中n<sub>c'</sub>为滤波器组个数，也就是下一层的通道数。写下这个假设的时候，用的步幅为1，并且没有Padding。如果你用了不同的步幅或者Padding。那么(n-f+1)数值就会变化。((n+2p-f)/s)+1。

---
#### 单层卷积网络
卷积神经网络的单层结构如下图所示：

![image](https://pic2.zhimg.com/v2-f1a98eeb40bec5858c3b91c4cece5f7b_r.jpg)

相比之前的卷积过程，CNN的单层结构多了激活函数ReLU和偏移量b。整个过程与标准神经网络的单层结构非常相似：

```math
Z^{[l]}=W^{[l]}A^{[l-1]}+b

A^{[l]}=g^{[l]}(Z^{[l]})
```
卷积运算对应着上式中的乘积运算，滤波器组数值对应着权重W<sup>[l]</sup>，所选的激活函数为ReLU。

我们来计算一下上图中参数的数目：每个滤波器组有3x3x3=27个参数，还有1个偏移量b，则每个滤波器组有27+1=28个参数，两个滤波器组总共包含28x2=56个参数。我们发现，选定滤波器组后，参数数目与输入图片尺寸无关。所以，就不存在由于图片尺寸过大，造成参数过多的情况。例如一张1000x1000x3的图片，标准神经网络输入层的维度将达到3百万，而在CNN中，参数数目只由滤波器组决定，数目相对来说要少得多，这是CNN的优势之一。

最后，我们来总结一下CNN单层结构的所有标记符号，设层数为l。
- f<sup>[l]</sup>=filter size
- p<sup>[l]</sup>=padding
- s<sup>[l]</sup>=stride
- n<sub>c</sub><sup>[l]</sup>=number of filters

输入维度为：

```math
 n_H^{[l-1]} * n_W^{[l-1]} * n_c^{[l-1]}
```
每个滤波器组维度为：

```math
f^{[l]}*f^{[l]}*n_c^{[l-1]}
```
权重维度为：

```math
f^{[l]}*f^{[l]}*n_c^{[l-1]}*n_c^{[l]}
```
偏置维度为：

```math
1*1*1*n_c^{[l]}
```
输出维度为：

```math
n_H^{[l]}*n_W^{[l]}*n_c^{[l]}
```
其中，


```math
n_H^{[l]}=\lfloor {{n_H^{[l-1]}+2p^{[l]}-f^{[l]}}\over s^{[l]}} +1\rfloor

n_W^{[l]}=\lfloor {{n_W^{[l-1]}+2p^{[l]}-f^{[l]}}\over s^{[l]}} +1\rfloor

```
如果有m个样本，进行向量化运算，相应的维度为：

```math
m*n_H^{[l]}*n_W^{[l]}*n_c^{[l]}
```

---
#### 简单卷积网络示例
下面介绍一个简单的CNN网络模型：

![image](https://pic3.zhimg.com/v2-f8f09993da3a6559b0c818af8d2742c6_r.jpg)

该CNN模型各层结构如上图所示。需要注意的是，a<sup>[3]</sup>的维度是7 x 7 x 40，将a<sup>[3]</sup>排列成1列，维度为1960 x 1，然后连接最后一级输出层。输出层可以是一个神经元，即二元分类(logistic)；也可以是多个神经元，即多分类(softmax)。最后得到预测输出。

值得一提的是，随着CNN层数的增加，n<sub>H</sub><sup>[l]</sup>和n<sub>W</sub><sup>[l]</sup>一般逐渐减小，而n<sub>c</sub><sup>[l]</sup>一般逐渐增大。

CNN有三种类型的layer:
- Convolution 层(CONV)
- Pooling 层(POOL)
- Fully connected 层(FC)

---
#### 池化层
Pooling layers 是CNN中用来减小尺寸，提高运算速度的，同样能够减小noise影响，让各特征更具有健壮性。

Pooling layers的做法比convolution layers简单许多，没有卷积运算，仅仅是在滤波器算子滑动区域内取最大值，即max pooling，这是最常用的做法。注意，超参数p很少在pooling layers中使用。

![image](https://pic1.zhimg.com/v2-7ddcea68ea7f5c2543d7a518ae400200_r.jpg)

Max pooling的好处是只保留区域内的最大值（特征），忽略其它值，降低noise影响，提高模型健壮性。而且，max pooling需要的超参数仅为滤波器尺寸f和滤波器步进长度s，没有其他参数需要模型训练得到，计算量很小。

如果是多个通道，那么就每个通道单独进行max pooling操作。

除了max pooling之外，还有一种做法：average pooling。顾名思义，average pooling就是在滤波器算子滑动区域计算平均值。

![image](https://pic4.zhimg.com/v2-6f055e85968234e192cc93a1e7261f72_r.jpg)

实际应用中，max pooling比average pooling更为常用。

---
#### 神经网络示例
下面介绍一个简单的数字识别的CNN的例子：

![image](https://pic4.zhimg.com/v2-d47ebc939f993e004ceb9f0c34a30b8f_r.jpg)

图中，CONV层后面紧接着一个POOL层，CONV1和POOL1构成第一层，CONV2和POOL2构成第二层。特别注意的是FC3和FC4为全连接层FC，它跟标准的神经网络结构一致。最后的输出层(softmax)由10个神经元构成。
随着神经网络深度的加深，高度n<sub>H</sub>和n<sub>W</sub>通常都会减小，从32x32到28x28，到14x14，到10x10，再到5x5。随着层数增加，高度和宽度都会减小，而通道数会增加，从3到8到16不断增加，然后得到一个全连接层。

在神经网络中，另一种常见模式就是一个或多个卷积后面跟随一个池化层，然后一个或多个卷积层后面再跟一个池化层，然后是几个全连接层，最后是一个softmax。这就是神经网络的另一种常见模式。

神经网络激活值形状，激活值大小和参数数量。输入大小为32x32x3，这些数做乘法，结果为3072，所以激活值a<sup>[0]</sup>有3072维，激活矩阵为32x32x3，输入层没有参数。

整个网络各层的尺寸和参数如下表所示：

layersize&parma | Activation shape |Activation Size | #parmaters
---|---|---|---
Input| (32,32,3)|3072|0
CONV1(f=5,s=1)| (28,28,8)|6272|(5x5+1)x8=208
POOL1|(14,14,8)|1568|0
CONV2(f=5,s=1)|(10,10,16)|1600|(5x5+1)x16=416
POOL2|(5,5,16)|400|0
FC3|(120,1)|120|400x120+1=48001
FC4|(84,1)|84|120x84+1=10081
Softmax|(10,1)|10|84x10+1=841

有几点需要注意：第一池化层和最大池化层没有参数；第二卷积层的参数相对较少，其实许多参数都内嵌于全连接层。观察可以发现，随着神经网络的加深，激活尺寸会逐渐变小，如果激活尺寸下降太快，也会影响到神经网络的性能。

---
#### 为什么使用卷积
相比于标准的神经网络，CNN的优势之一就是参数数目要少得多。参数数目少的原因有两个：
- 参数共享：一个特征检测器(例如垂直边缘检测)对图片的某块区域有用，同时也可能作用在图片的其它区域。
- 连接的稀疏性：因为滤波器算子尺寸限制，每一层的每个输入只与输出部分区域内有关。

除此之外，由于CNN参数数目较小，所需的训练样本就相对较少，从而一定程度上不容易发生过拟合现象。而且CNN比较擅长捕捉区域位置偏移。也就是说CNN进行物体检测时，不太受物体所处图片位置的影响，增加检测的准确性和系统的健壮性。

