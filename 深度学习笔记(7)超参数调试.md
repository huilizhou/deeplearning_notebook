#### 调试处理

深度神经网络需要调试的超参数(Hyperparameters)较多，包括：
- &alpha;：学习因子
- &beta;：动量梯度下降因子
- &beta;<sub>1</sub>,&beta;<sub>2</sub>,&epsilon;：Adam 算法参数
- #layers：神经网络层数
- #hidden units：各隐藏层神经元个数
- learning rate decay：学习因子下降参数
- mini-bach size：批量训练样本包含的样本个数

超参数之间也有重要性差异。通常说来，学习因子&alpha;是最重要的超参数，也是需要重点调试的超参数。动量梯度下降因子&beta;、各隐藏层神经元个数#hidden units和mini-bach size 的重要性仅次于&alpha;。然后就是设计网络层数#layers和学习因子下降参数learning rate decay。最后是Adam算法的三个重要参数&beta;<sub>1</sub>,&beta;<sub>2</sub>,&epsilon;一般设置为0.9，0.999和10<sup>-8</sup>。不需要反复调试，当然这里的超参数重要性的排名并不是绝对的，具体情况具体分析。

如何选择和调试超参数？传统的机器学习中，我们对每个参数等距离选取任意个数的点，然后，分别使用不同点对应的参数组合进行训练，最后根据验证集上的表现好坏，来选定最佳的参数。例如有两个待调试的参数，分别在每个参数上选取5个点，这样构成了5x5=25中参数组合，如下图所示：

![image](https://pic2.zhimg.com/80/v2-a382212cff5b23a79aa690ad83c384ee_hd.jpg)

这种做法在参数较少的时候效果较好。但是在深度神经网络模型中，我们一般不采用这种均匀间隔取点的方法，比较好的做法是使用随机选择。也就是说，对于上面的这个例子，我们随机选择25个点作为待调试的超参数，如下图所示：

![image](https://pic3.zhimg.com/80/v2-ddfd83b61ab06fc867900ae8e971a525_hd.jpg)

随机化选择参数的目的是为了尽可能地得到更多种参数组合。还是上面的例子，如果使用均匀采样的话，每种参数只能有25种可能的情况，因此更有可能得到最佳的参数组合。

这种做法带来的好处是对重要性不同的参数之间的选择效果更好。假设hyperparameter1为 &alpha; ，hyperparameter2为 &varepsilon; ，显然二者的重要性是不一样的。如果使用第一种均匀采样的方法， &varepsilon; 的影响很小，相当于只选择了5个 &alpha; 值。而如果使用第二种随机采样的方法， &varepsilon; 和 &alpha; 都有可能选择25种不同值。这大大增加了 &alpha; 调试的个数，更有可能选择到最优值。其实，在实际应用中完全不知道哪个参数更加重要的情况下，随机采样的方式能有效解决这一问题，但是均匀采样做不到这点。

在经过随机采样之后，我们可能得到某些区域模型的表现较好。然而为了得到更加精确的最佳参数，我们应该继续对选定的区域进行由粗到细的采样(coarse to fine sampling scheme)，也就是放大表现较好的区域，再对此区域做更密集的随机采样。例如，对下图中右下角的方形区域再做25点的随机采样，以获得最佳参数。

![image](https://pic4.zhimg.com/v2-1673a1ea73887730fa17836c0e2f347f_r.jpg)

---
#### 为超参数选择合适的范围
上部分讲的调试参数使用随机采样，对于某些超参数是可以进行尺度均匀采样的，但是某些超参数需要选择不同的合适尺度进行随机采样。

例如对于超参数#layers 和#hidden units，都是正整数，是可以进行均匀随机采样的，即超参数每次变化的尺度都是一致的(如每次变化为1，犹如一个刻度尺一样，刻度是均匀的)。

但是，某些超参数，可能需要非均匀随机采样(即非均匀刻度尺)。例如超参数&alpha;，待调范围是[0.0001,1]。如果使用均匀随机采样，那么有90%的采样点分布在[0.1,1]之间。只有10%分布在[0.0001,0.1]之间。这在实际应用中不太好，因为最佳的&alpha;值可能主要分布在[0.0001,0.1]之间，而[0.1,1]范围内&alpha;值效果并不好。因此我们更为关注的区间是[0.0001,0.1]，应该在这一区间内细分更多的刻度。

通常的做法是将linear scale转换为log scale，将均匀尺度转化为非均匀尺度，然后再在log scale下进行均匀采样。这样，[0.0001, 0.001]，[0.001, 0.01]，[0.01, 0.1]，[0.1, 1]各个区间内随机采样的超参数个数基本一致，也就扩大了之前[0.0001, 0.1]区间内采样值个数。

![image](https://pic3.zhimg.com/v2-afd9848a577310a75139bf58ae57720a_r.jpg)

一般解法是，如果线性区间为[a, b]，令m=log(a)，n=log(b)，则对应的log区间为[m,n]。对log区间的[m,n]进行随机均匀采样，然后得到的采样值r，最后反推到线性区间，即 10^r 。 10^r 就是最终采样的超参数。相应的Python语句为：

```
m = np.log10(a)
n = np.log10(b)
r = np.random.rand()
r = m + (n-m)*r
r = np.power(10,r)
```
除了 &alpha;之外，动量梯度因子 &beta; 也是一样，在超参数调试的时候也需要进行非均匀采样。一般 &beta;的取值范围在[0.9,0.999]之间，那么 1-&beta;的取值范围就在[0.001,0.1]之间。那么直接对 1-&beta;在[0.001,0.1]区间内进行log变换即可。

这里解释下为什么&beta;也需要向&alpha; 那样做非均匀采样。假设&beta;从0.9000变化为0.9005，那么 1/1-&beta; 基本没有变化。但假设 &beta; 从0.9990变化为0.9995，那么1/1-&beta;前后差别1000。&beta;越接近1，指数加权平均的个数越多，变化越大。所以对&beta;接近1的区间，应该采集得更密集一些。

希望能帮助你选择合适的标尺，来给超参数取值。如果你没有在超参数选择中作出正确的标尺决定，别担心，即使你在均匀的标尺上取值，如果数值总量较多的话，你也会得到不错的结果，尤其是应用到从粗到细的搜素方法，在之后的迭代中，你还是会聚焦到有用的超参数取值范围上。

---
#### 超参数训练的实践
经过调试选择的超参数并不是一成不变的，一段时间之后，需要根据新的数据和实际情况，再次调试超参数，以获得实时的最佳模型。

在训练深度神经网络时，一种是受计算能力所限，我们只能对一个模型进行训练，调试不同的超参数，使得这个模型有最佳表现。我们称之为Babysitting one model。另外一种情况是可以对多个模型同时进行训练，每个模型调试不同的参数， 根据表现情况，选择最佳的模型，每个模型上调试不同的参数，根据表现情况，选择最佳的模型，我们称之为Training many models in parallel。

![image](https://pic2.zhimg.com/80/v2-b310f885bdd2d82b5c5b94eef1d47498_hd.jpg)

因为第一种情况只使用一个模型，所以类比做Caviar(鱼子) approach。使用哪种模型是由计算资源、计算能力所决定的。一般说来，对于非常0复杂或者数据量很大的模型，使用Panda(熊猫) approach更多一些。

---
#### 归一化网络的激活函数
Sergey Ioffe和Christian Szegedy两位学者提出了Batch Normalization方法。Batch Normalization不仅可以让调试超参数更加简单，而且可以让神经网络模型更加“健壮”。也就是说较好模型可接受的超参数范围更大一些，包容性更强，使得更容易去训练一个深度神经网络。接下来，我们就来介绍什么是Batch Normalization，以及它是如何工作的。

提到过在训练神经网络时，标准化输入可以提高训练的速度。方法是对训练数据集进行归一化的操作，即将原始数据减去其均值 &mu; 后，再除以其方差 &sigma;<sup>2</sup>。但是标准化输入只是对输入进行了处理，那么对于神经网络，又该如何对各隐藏层的输入进行标准化处理呢？

其实在神经网络中，第l层隐藏层的输入就是第l-1层隐藏层的输出A<sup>[l-1]</sup>。对A<sup>[l-1]</sup>进行标准化处理就是Batch Normalization。值得注意的是，在实际应用中，一般是对Z<sup>[l-1]</sup>进行标准化处理而不是A<sup>[l-1]</sup>，其实差别不是很大。

Batch Normalization 对第l层隐藏层的输入Z<sup>[l-1]</sup>做如下标准化处理，忽略上标[l-1]：

```math
\mu={1\over m}\sum_iz^{(i)}

\sigma^2={1\over m}\sum_i(z^{(i)}-\mu)^2

z_{norm}^{(i)}={{z^{(i)}-\mu}\over {\sqrt {\sigma^2+\varepsilon}}}
```
其中，m是单个mini-batch 包含样本个数，&epsilon;是为了防止分母为零，可取值为10<sup>-8</sup>。这样，使得该隐藏层的所有输入z<sup>(i)</sup>均值为0，方差为1。

但是大部分情况并不希望所有的z<sup>(i)</sup>均值都为0，方差都为1，这也太不合理了。通常需要对z<sup>(i)</sup>进行进一步处理：

```math
\tilde z=\gamma· z_{norm}^{(i)}+\beta
```
上式中，&gamma;和&beta;是learnable parameters，类似于W和b一样，可以通过梯度下降等算法求得。这里得作用是让&gamma; 和&beta;的作用是让 z&tilde; <sup>(i)</sup> 的均值和方差为任意值，只需调整其值就可以了。

```math
\gamma=\sqrt{\sigma^2+\varepsilon}, \beta=\mu
```
可见，设置 &gamma;和&beta;为不同的值，可以得到任意的均值和方差。

值得注意的是，输入的标准化处理Normalizing inputs和隐藏层的标准化处理Batch Normalization是有区别的。Normalizing inputs使所有输入的均值为0，方差为1。而Batch Normalization可使各隐藏层输入的均值和方差为任意值。实际上，从激活函数的角度来说，如果各隐藏层的输入均值在靠近0的区域即处于激活函数的线性区域，这样不利于训练好的非线性神经网络，得到的模型效果也不会太好。这也解释了为什么需要用 &gamma; 和 &beta; 来对 z<sup>[l]</sup><sup>(i)</sup>作进一步处理。

比如，如果你有sigmoid函数，你不想让你的值全部集中在这里，你想要使他们有更大的方差，或不是0的平均值，以便更好的利用非线性的sigmoid函数。而不是所有的值都集中于这个线性版本中，这就是为什么有了&gamma;和&beta;两个参数之后，你可以确保所有的z<sup>(i)</sup>都是你想赋予的值。那里，均值和方差由两参数控制，即&gamma;和&beta;，学习算法可以设置为任何值，所以它真正的作用是，使隐藏单元的均值和方差标准化，即z<sup>(i)</sup>有固定的均值和方差，均值和方差可以使0和1，也可以是其他值，它是由&gamma;和&beta;两参数控制的。

---
#### 将 Batch Norm拟合进神经网络
我们已经知道了如何对某一单一隐藏层的所有神经元进Batch Norm，接下来将研究如何把Batch Norm应用到整个神经网络中。

对于L层神经网络，经过Batch Norm 的作用，整体流程如下：

![image](https://pic4.zhimg.com/v2-27530f0948081506bcc3b43563a9e7be_r.jpg)

实际上，Batch Norm经常使用在mini-bacth上，这也是名称的由来。

值得注意的是，因为Batch Norm 对各隐藏层Z<sup>[l]</sup>=W<sup>[l]</sup>A<sup>[l-1]</sup>+b<sup>[l]</sup>有去均值的操作，所以这里的常数项b<sup>[l]</sup>可以消去，其数值效果完全可以由&tilde; Z<sup>[l]</sup>中的&beta;来实现。因此我们在使用Batch Norm 的时候，可以忽略各隐藏层的常数项b<sup>[l]</sup>。在使用梯度下降算法时，分别对W<sup>[l]</sup>,&beta;<sup>[l]</sup>和&gamma;<sup>[l]</sup>进行迭代更新。

最后请记住z<sup>[l]</sup>的维数，在这个例子中，维数会是(n<sup>[l]</sup>,1)，b<sup>[l]</sup>的尺寸为(n<sup>[l]</sup>,1)，如果是l层隐藏单元的数量，则&beta;<sup>[l]</sup>和&gamma;<sup>[l]</sup>的维度也是(n<sup>[l]</sup>,1)，因为这是你隐藏层的数量，你有n<sup>[l]</sup>隐藏单元，所以&beta;<sup>[l]</sup>和&gamma;<sup>[l]</sup>用来将每个隐藏层的均值和方差缩放为网络想要的值。

让我们来总结一下关于如何用batch归一化来应用梯度下降法，假设你在使用mini-batch 梯度下降法，你运行t=1到batch数量的for循环，你会在mini-batch X<sup>{t}</sup>上应用正向prop，每个隐藏层都应用正向prop。用Batch归一化代替z<sup>[l]</sup>为&tilde;z<sup>[l]</sup>。接下来，它确保在这个mini-batch中，z值有归一化的均值和方差，然后你用反向prop计算d&omega;<sup>[l]</sup>和db<sup>[l]</sup>，以及l层的所有参数，即d&beta;<sup>[l]</sup>和d&gamma;<sup>[l]</sup>。严格来说，因为你已经去掉b，这部分其实已经丢掉了，最后，你更新这些参数：

```math
\omega^{[l]}=\omega^{[l]}-\alpha d\omega^{[l]}

\beta^{[l]}=\beta^{[l]}-\alpha d\beta^{[l]}

\gamma^{[l]}=\gamma^{[l]}-\alpha d\gamma^{[l]}
```



除了传统的梯度下降算法之外，还可以使用我们之前介绍过的动量梯度下降、RMSprop或者Adam等优化算法。

---
#### Batch Norm 为什么奏效？
我们可以把输入特征做均值为0，方差为1 的规范化处理，来加快学习速度。而Batch Norm也是对隐藏层各神经元的输入做类似的规范化处理。总的来说，Batch Norm 不仅能够提高神经网络训练的速度，而且能够让神经网络的权重W更新更加“稳健”，尤其在深层神经网络中更加明显，比如神经网络很后面的W对前面的W包容性更强，即前面的W变化对后面W造成的影响很小，整体网络更加健壮。

举个例子来说明，假如用一个浅层神经网络(类似对数几率回归)来训练识别猫的模型，如下图所示，所提供的训练样本均是黑猫，然后，用这个训练得到的模型来对各种颜色的猫样本进行测试，测试的结果可能并不好。其原因是训练样本不具有一般性(即不是所有的猫都是黑猫)，这种训练样本(黑猫)和测试样本(猫)分布的变化称之为covariate shift。

![image](https://pic2.zhimg.com/80/v2-4e65e15653913e876df5a6bc5627b861_hd.jpg)

对于这种情况，如果实际应用的样本与训练样本分布不同，即产生了covariate shift，则一般是要对模型重新进行训练的。在神经网络中，covariate shift 会导致模型预测效果变差，重新训练的模型隐藏层的W<sup>[l]</sup>和B<sup>[l]</sup>均产生偏移、变化。而Batch Norm 减少了各层W<sup>[l]</sup>和B<sup>[l]</sup>的耦合性，让各层更加独立，实现自我训练学习的效果。也就是说，如果输入层发生了convariate shift，那么因为Batch Norm 的作用，对各隐藏层输出Z<sup>[l]</sup>进行均值和方差的归一化处理，W<sup>[l]</sup>和B<sup>[l]</sup>更加稳定，使得原来的模型也有不错的表现。针对上面这个黑猫的例子，如果我们使用深层神经网络，使用Batch Norm，那么该模型对花猫的识别能力应该还是不错的。

从另一方面来说，Batch Norm也起到轻微正则化的效果。具体表现在：
- 每个mini-batch 都进行均值为0，方差为1的归一化操作
- 每个mini-batch中，对各个隐藏层的Z<sup>[l]</sup>添加了随机噪声，效果类似于Dropout
- mini-batch 越小，正则化效果越明显

但是Batch Norm 的正则化效果比较微弱，正则化也不是Batch Norm的主要功能。

---
#### 测试时的Batch Norm
训练过程中，Batch Norm 是对单个mini-batch进行操作的，但在测试过程中，如果是单个样本，该如何使用Batch Norm 进行处理呢？

首先，回顾一下训练过程中Batch Norm 的主要过程：

```math
\mu ={1\over m}\sum_iz^{(i)}

\sigma^2={1\over m}\sum_i(z^{(i)}-\mu)^2

z_{norm}^{(i)}={{z^{(i)}-\mu}\over {\sqrt{\sigma^2+\varepsilon}}}

\tilde z^{(i)}=\gamma· z_{norm}^{(i)}+\beta
```
其中，&mu;和&sigma;<sup>2</sup>是对单个mini-batch中所有m个样本进行求得的。在测试过程中，如果只有一个样本，求其均值和方差是没有意义的，就需要对&mu;和&sigma;<sup>2</sup>进行估计。估计的方法有很多，理论上我们可以将所有训练集放入最终的神经网络模型中，然后将每个隐藏层计算得到的，&mu;<sup>[l]</sup>和&sigma;<sup>2</sup><sup>[l]</sup>直接作为测试过程&mu;和&sigma;<sup>2</sup>来使用。但是，实际应用中一般不使用这种方法，而是使用我们之前介绍过的指数加权平均(exponentially weighted average)的方法来预测测试过程单个样本的&mu;和&sigma;<sup>2</sup>。

指数加权平均的做法也很简单，对于第l层隐藏层，考虑所有mini-batch在该该隐藏层下的&mu;<sup>[l]</sup>和&sigma;<sup>2</sup><sup>[l]</sup>，然后使用指数加权平均的方法来预测得到当前的单个样本的&mu;<sup>[l]</sup>和&sigma;<sup>2</sup><sup>[l]</sup>。这样就实现了对测试过程单个样本的均值和方差估计。最后，再利用训练过程得到的&gamma;和&beta;值计算出各层的 &tilde; z<sup>(i)</sup>值。

---
#### Softmax 回归
之前我们介绍的都是二分类问题，神经网络输出层都只有一个神经元。表示预测输出&hat;y是正类的概率P(y=1|x),&hat;y>0.5则判断为正类，&hat;y< 0.5则判断为负类。

对于多分类问题，用C表示种类个数，神经网络中输出层就有C个神经元，即n<sup>[l]</sup>=C。其中，每个神经元的输出依次对应属于该类的种类，即P(y=c|x)。为了处理多分类问题，我们一般使用Softmax回归模型。Softmax回归模型输出层的激活函数如下所示：

```math
z^{[L]}=W^{[l]}a^{[L-1]}+b^{[L]}

a_i^{[L]}={e^{z_{i}^{[L]}}\over {\sum_{i=1}^C e^{z_{i}^{[L]}}}}
```
输出层每个神经元的输出a<sub>i</sub><sup>[L]</sup>对应于属于该类的概率，满足：

```math
\sum_{i=1}^C a_i^{[L]}=1
```
下面给出几个简单的线性多分类的例子：

![image](https://pic2.zhimg.com/v2-b78a672a1188994ab3f725ce86bf9807_r.jpg)

如果使用神经网络，特别是深层神经网络，可以得到更复杂、更精确的非线性模型。

---
#### 训练一个softmax分类器
Softmax classifier的训练过程与我们之前介绍的二元分类问题有所不同。先来看一下softmax classifier的loss function。举例来说，假如C=4，某个样本的预测输出 &hat; y 和真实输出y为：

```math
\hat y=\begin{bmatrix}0.3\\0.2\\0.1\\0.4
\end{bmatrix}

y=\begin{bmatrix}0\\1\\0\\0
\end{bmatrix}

```
从 &hat; y 值来看， P(y=4|x)=0.4 ，概率最大，而真实样本属于第2类，因此该预测效果不佳。我们定义softmax classifier的loss function为：

```math
L(\hat y,y)=-\sum_{j=1}^4y_j·log\hat y_j
```
当j=2时，y<sub>2</sub>=1，其他情况下，y<sub>j</sub>=0。
```math
L(\hat y,y)=-y_2·log\hat y_2
```
所有m个样本的cost fuction 为：

```math
J={1\over m}\sum_{i=1}^m L(\hat y,y)
```
其预测输出向量为A<sup>[L]</sup>。

softmax classifier的反向传播过程仍然使用梯度下降算法，其推导过程与二元分类有一点点不一样。因为只有输出层的激活函数不一样，我们先推导 dZ<sup>[L]</sup>:

```math
da^L=={1\over a^{[L]}}

{∂a^{[L]}\over ∂z^{[L]}}={∂\over ∂∂z^{[L]}}·({e^{z_{i}^{[L]}}\over {\sum_{i=1}^C e^{z_{i}^{[L]}}}})=a^{[L]}·(1-a^{[L]})

dz^{[L]}=da^{[L]}·{∂a^{[L]}\over ∂z^{[L]}}=a^{[L]}-1=a^{[L]}-y
```
对于所有m个训练样本：

```math
dZ^{[L]}=A^{[L]}-Y
```
可见dZ<sup>[L]</sup>的表达式与二元分类结果是一致的，虽然推导过程不大一样。然后就可以继续进行反向传播过程的梯度下降算法了，推动过程与二元分类神经网络完全一致。

---
#### 深度学习框架 Tensorflow



